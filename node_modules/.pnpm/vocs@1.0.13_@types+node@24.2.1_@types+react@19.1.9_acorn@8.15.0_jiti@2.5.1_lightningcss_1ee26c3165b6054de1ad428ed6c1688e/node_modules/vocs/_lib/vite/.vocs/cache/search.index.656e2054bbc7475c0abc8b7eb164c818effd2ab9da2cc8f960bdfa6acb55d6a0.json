"{\"value\":{\"mdx\":\"# Model Discovery\\n\\nLearn how to find and select the perfect AI models for your specific use cases.\\n\\n## Overview\\n\\nAiMo Network hosts hundreds of AI models from various providers. Our model discovery system helps you find the right model based on your requirements for performance, cost, and capabilities.\\n\\n## Browsing Models\\n\\n### Model Catalog\\n\\nThe [model catalog](https://dashboard.aimo.network/models) provides a comprehensive view of all available models:\\n\\n- **Model cards** with detailed descriptions and capabilities\\n- **Real-time pricing** from different providers\\n- **Performance metrics** including latency and quality scores\\n- **Availability status** and uptime statistics\\n\\n### Filtering Options\\n\\nFilter models by various criteria:\\n\\n```bash\\n# List all models\\ncurl -X GET https://api.aimo.network/v1/models \\\\\\n  -H \\\"Authorization: Bearer YOUR_API_KEY\\\"\\n\\n# Filter by model type\\ncurl -X GET https://api.aimo.network/v1/models?type=text-generation \\\\\\n  -H \\\"Authorization: Bearer YOUR_API_KEY\\\"\\n\\n# Filter by provider\\ncurl -X GET https://api.aimo.network/v1/models?provider=openai \\\\\\n  -H \\\"Authorization: Bearer YOUR_API_KEY\\\"\\n```\\n\\n## Model Categories\\n\\n### Language Models\\n\\n#### Chat & Completion Models\\nPerfect for conversational AI and text generation:\\n\\n| Model | Provider | Use Case | Cost per 1K tokens |\\n|-------|----------|----------|---------------------|\\n| GPT-4 | OpenAI | Advanced reasoning, complex tasks | $0.03 |\\n| GPT-3.5 Turbo | OpenAI | Fast chat, simple completion | $0.002 |\\n| Claude-3 | Anthropic | Analysis, writing, coding | $0.015 |\\n| Llama 2 70B | Meta | Open-source alternative | $0.001 |\\n\\n#### Code Generation Models\\nSpecialized for programming tasks:\\n\\n| Model | Provider | Specialization | Cost per 1K tokens |\\n|-------|----------|----------------|---------------------|\\n| CodeT5+ | Salesforce | Multi-language code | $0.004 |\\n| GitHub Copilot | GitHub | IDE integration | $0.006 |\\n| CodeGen | Salesforce | Large-scale code generation | $0.003 |\\n\\n### Vision Models\\n\\n#### Image Generation\\nCreate images from text descriptions:\\n\\n| Model | Provider | Style | Cost per image |\\n|-------|----------|-------|----------------|\\n| DALL-E 3 | OpenAI | Photorealistic | $0.040 |\\n| Midjourney | Midjourney | Artistic | $0.025 |\\n| Stable Diffusion XL | Stability AI | Versatile | $0.015 |\\n\\n#### Image Analysis\\nAnalyze and describe images:\\n\\n| Model | Provider | Capabilities | Cost per request |\\n|-------|----------|-------------|------------------|\\n| GPT-4V | OpenAI | General vision, OCR | $0.020 |\\n| Claude Vision | Anthropic | Document analysis | $0.018 |\\n| LLaVA | Various | Open-source vision | $0.005 |\\n\\n### Embedding Models\\n\\nFor semantic search and similarity:\\n\\n| Model | Provider | Dimensions | Cost per 1K tokens |\\n|-------|----------|------------|---------------------|\\n| text-embedding-ada-002 | OpenAI | 1536 | $0.0001 |\\n| all-MiniLM-L6-v2 | Sentence Transformers | 384 | $0.0001 |\\n| e5-large-v2 | Microsoft | 1024 | $0.0002 |\\n\\n## Model Selection Criteria\\n\\n### Performance Factors\\n\\n#### Quality Metrics\\n- **Accuracy scores** on benchmark datasets\\n- **Human evaluation ratings** from users\\n- **Task-specific performance** (BLEU, ROUGE, etc.)\\n- **Safety and bias assessments**\\n\\n#### Speed & Efficiency\\n- **Average latency** per request\\n- **Throughput** (requests per second)\\n- **Time to first token** for streaming\\n- **Scalability** under load\\n\\n### Cost Considerations\\n\\n#### Pricing Models\\n- **Per-token pricing** for language models\\n- **Per-image pricing** for generation models\\n- **Per-request pricing** for embeddings\\n- **Volume discounts** for high usage\\n\\n#### Cost Optimization Tips\\n1. **Compare providers** for the same model\\n2. **Monitor usage patterns** to identify optimization opportunities\\n3. **Use caching** for repeated requests\\n4. **Choose appropriate model sizes** for your use case\\n\\n### Provider Reliability\\n\\n#### Availability Metrics\\n- **Uptime percentage** (99.9%+ recommended)\\n- **Mean time to recovery** (MTTR)\\n- **Geographic distribution** for reduced latency\\n- **Status page** transparency\\n\\n## Model Comparison\\n\\n### Side-by-Side Comparison\\n\\nUse our comparison tool to evaluate models:\\n\\n```python\\nfrom aimo import AimoClient\\n\\nclient = AimoClient(api_key=\\\"your_api_key\\\")\\n\\n# Compare models for a specific task\\ncomparison = client.models.compare(\\n    models=[\\\"gpt-4\\\", \\\"claude-3\\\", \\\"llama-2-70b\\\"],\\n    task=\\\"text-summarization\\\",\\n    metrics=[\\\"quality\\\", \\\"speed\\\", \\\"cost\\\"]\\n)\\n\\nprint(comparison)\\n```\\n\\n### Benchmark Results\\n\\nPopular benchmarks across model types:\\n\\n#### Language Models\\n- **MMLU** (Massive Multitask Language Understanding)\\n- **HellaSwag** (Common sense reasoning)\\n- **HumanEval** (Code generation)\\n- **GSM8K** (Mathematical reasoning)\\n\\n#### Vision Models\\n- **COCO** (Object detection and segmentation)\\n- **ImageNet** (Image classification)\\n- **VQA** (Visual Question Answering)\\n\\n## Testing Models\\n\\n### Quick Testing\\n\\nTest models directly in your browser:\\n\\n1. Go to [API Playground](https://dashboard.aimo.network/playground)\\n2. Select a model from the dropdown\\n3. Enter your prompt or input\\n4. Adjust parameters (temperature, max tokens, etc.)\\n5. Run the test and review results\\n\\n### Programmatic Testing\\n\\nTest multiple models with the same input:\\n\\n```python\\nmodels_to_test = [\\\"gpt-4\\\", \\\"claude-3\\\", \\\"llama-2-70b\\\"]\\nprompt = \\\"Explain quantum computing in simple terms\\\"\\n\\nresults = {}\\nfor model in models_to_test:\\n    response = client.chat.completions.create(\\n        model=model,\\n        messages=[{\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}],\\n        max_tokens=200\\n    )\\n    results[model] = {\\n        \\\"response\\\": response.choices[0].message.content,\\n        \\\"latency\\\": response.meta.latency_ms,\\n        \\\"cost\\\": response.meta.cost\\n    }\\n\\n# Compare results\\nfor model, result in results.items():\\n    print(f\\\"{model}: {result['latency']}ms, ${result['cost']}\\\")\\n```\\n\\n## Model Recommendations\\n\\n### By Use Case\\n\\n#### Customer Support Chatbots\\n**Recommended**: GPT-3.5 Turbo\\n- **Why**: Fast responses, good comprehension, cost-effective\\n- **Alternative**: Claude-3 for more nuanced conversations\\n\\n#### Content Generation\\n**Recommended**: GPT-4\\n- **Why**: High quality, creative outputs, good instruction following\\n- **Alternative**: Claude-3 for specific writing styles\\n\\n#### Code Analysis\\n**Recommended**: GPT-4 or CodeT5+\\n- **Why**: Strong reasoning, multi-language support\\n- **Alternative**: GitHub Copilot for IDE integration\\n\\n#### Image Generation\\n**Recommended**: DALL-E 3\\n- **Why**: High quality, good prompt adherence\\n- **Alternative**: Midjourney for artistic styles\\n\\n### By Budget\\n\\n#### Budget-Conscious\\n- **Language**: Llama 2, GPT-3.5 Turbo\\n- **Images**: Stable Diffusion models\\n- **Embeddings**: Open-source Sentence Transformers\\n\\n#### Performance-First\\n- **Language**: GPT-4, Claude-3\\n- **Images**: DALL-E 3, Midjourney Pro\\n- **Embeddings**: OpenAI Ada-002\\n\\n## Staying Updated\\n\\n### New Model Alerts\\n\\nSubscribe to notifications for:\\n- **New model releases** in your categories of interest\\n- **Price changes** from your preferred providers\\n- **Performance improvements** and updates\\n\\n### Model Versioning\\n\\nTrack model versions and updates:\\n- **Changelog** for each model version\\n- **Backward compatibility** information\\n- **Migration guides** for version upgrades\\n\\n## Next Steps\\n\\nNow that you know how to discover models:\\n\\n1. **[Make your first request](/user-guide/making-requests)** with a selected model\\n2. **[Set up authentication](/user-guide/authentication)** for secure access\\n3. **[Monitor usage and costs](/user-guide/billing)** to optimize spending\\n\\nNeed help choosing? Contact our team at models@aimo.network for personalized recommendations.\\n\",\"document\":[{\"href\":\"/user-guide/model-discovery#model-discovery\",\"html\":\"</header>\\n<p>Learn how to find and select the perfect AI models for your specific use cases.</p>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#model-discovery\",\"isPage\":true,\"text\":\"\\nLearn how to find and select the perfect AI models for your specific use cases.\\n\",\"title\":\"Model Discovery\",\"titles\":[]},{\"href\":\"/user-guide/model-discovery#overview\",\"html\":\"\\n<p>AiMo Network hosts hundreds of AI models from various providers. Our model discovery system helps you find the right model based on your requirements for performance, cost, and capabilities.</p>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#overview\",\"isPage\":false,\"text\":\"\\nAiMo Network hosts hundreds of AI models from various providers. Our model discovery system helps you find the right model based on your requirements for performance, cost, and capabilities.\\n\",\"title\":\"Overview\",\"titles\":[\"Model Discovery\"]},{\"href\":\"/user-guide/model-discovery#browsing-models\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#browsing-models\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Browsing Models\",\"titles\":[\"Model Discovery\"]},{\"href\":\"/user-guide/model-discovery#model-catalog\",\"html\":\"\\n<p>The <a href=\\\"https://dashboard.aimo.network/models\\\">model catalog</a> provides a comprehensive view of all available models:</p>\\n<ul>\\n<li><strong>Model cards</strong> with detailed descriptions and capabilities</li>\\n<li><strong>Real-time pricing</strong> from different providers</li>\\n<li><strong>Performance metrics</strong> including latency and quality scores</li>\\n<li><strong>Availability status</strong> and uptime statistics</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#model-catalog\",\"isPage\":false,\"text\":\"\\nThe model catalog provides a comprehensive view of all available models:\\n\\nModel cards with detailed descriptions and capabilities\\nReal-time pricing from different providers\\nPerformance metrics including latency and quality scores\\nAvailability status and uptime statistics\\n\\n\",\"title\":\"Model Catalog\",\"titles\":[\"Model Discovery\",\"Browsing Models\"]},{\"href\":\"/user-guide/model-discovery#filtering-options\",\"html\":\"\\n<p>Filter models by various criteria:</p>\\n<pre class=\\\"shiki shiki-themes github-light github-dark-dimmed\\\" style=\\\"background-color:#fff;--shiki-dark-bg:#22272e;color:#24292e;--shiki-dark:#adbac7\\\" tabindex=\\\"0\\\"><code><span class=\\\"line\\\"><span style=\\\"color:#6A737D;--shiki-dark:#768390\\\"># List all models</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#6F42C1;--shiki-dark:#F69D50\\\">curl</span><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\"> -X</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> GET</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> https://api.aimo.network/v1/models</span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\"> \\\\</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\">  -H</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> &quot;Authorization: Bearer YOUR_API_KEY&quot;</span></span>\\n<span class=\\\"line\\\" data-empty-line=\\\"true\\\"> </span>\\n<span class=\\\"line\\\"><span style=\\\"color:#6A737D;--shiki-dark:#768390\\\"># Filter by model type</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#6F42C1;--shiki-dark:#F69D50\\\">curl</span><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\"> -X</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> GET</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> https://api.aimo.network/v1/models?type=text-generation</span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\"> \\\\</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\">  -H</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> &quot;Authorization: Bearer YOUR_API_KEY&quot;</span></span>\\n<span class=\\\"line\\\" data-empty-line=\\\"true\\\"> </span>\\n<span class=\\\"line\\\"><span style=\\\"color:#6A737D;--shiki-dark:#768390\\\"># Filter by provider</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#6F42C1;--shiki-dark:#F69D50\\\">curl</span><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\"> -X</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> GET</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> https://api.aimo.network/v1/models?provider=openai</span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\"> \\\\</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\">  -H</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> &quot;Authorization: Bearer YOUR_API_KEY&quot;</span></span></code></pre>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#filtering-options\",\"isPage\":false,\"text\":\"\\nFilter models by various criteria:\\n# List all models\\ncurl -X GET https://api.aimo.network/v1/models \\\\\\n  -H &quot;Authorization: Bearer YOUR_API_KEY&quot;\\n \\n# Filter by model type\\ncurl -X GET https://api.aimo.network/v1/models?type=text-generation \\\\\\n  -H &quot;Authorization: Bearer YOUR_API_KEY&quot;\\n \\n# Filter by provider\\ncurl -X GET https://api.aimo.network/v1/models?provider=openai \\\\\\n  -H &quot;Authorization: Bearer YOUR_API_KEY&quot;\\n\",\"title\":\"Filtering Options\",\"titles\":[\"Model Discovery\",\"Browsing Models\"]},{\"href\":\"/user-guide/model-discovery#model-categories\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#model-categories\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Model Categories\",\"titles\":[\"Model Discovery\"]},{\"href\":\"/user-guide/model-discovery#language-models\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#language-models\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Language Models\",\"titles\":[\"Model Discovery\",\"Model Categories\"]},{\"href\":\"/user-guide/model-discovery#chat--completion-models\",\"html\":\"\\n<p>Perfect for conversational AI and text generation:</p>\\n<table><thead><tr><th>Model</th><th>Provider</th><th>Use Case</th><th>Cost per 1K tokens</th></tr></thead><tbody><tr><td>GPT-4</td><td>OpenAI</td><td>Advanced reasoning, complex tasks</td><td>$0.03</td></tr><tr><td>GPT-3.5 Turbo</td><td>OpenAI</td><td>Fast chat, simple completion</td><td>$0.002</td></tr><tr><td>Claude-3</td><td>Anthropic</td><td>Analysis, writing, coding</td><td>$0.015</td></tr><tr><td>Llama 2 70B</td><td>Meta</td><td>Open-source alternative</td><td>$0.001</td></tr></tbody></table>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#chat--completion-models\",\"isPage\":false,\"text\":\"\\nPerfect for conversational AI and text generation:\\nModelProviderUse CaseCost per 1K tokensGPT-4OpenAIAdvanced reasoning, complex tasks$0.03GPT-3.5 TurboOpenAIFast chat, simple completion$0.002Claude-3AnthropicAnalysis, writing, coding$0.015Llama 2 70BMetaOpen-source alternative$0.001\\n\",\"title\":\"Chat &amp; Completion Models\",\"titles\":[\"Model Discovery\",\"Model Categories\",\"Language Models\"]},{\"href\":\"/user-guide/model-discovery#code-generation-models\",\"html\":\"\\n<p>Specialized for programming tasks:</p>\\n<table><thead><tr><th>Model</th><th>Provider</th><th>Specialization</th><th>Cost per 1K tokens</th></tr></thead><tbody><tr><td>CodeT5+</td><td>Salesforce</td><td>Multi-language code</td><td>$0.004</td></tr><tr><td>GitHub Copilot</td><td>GitHub</td><td>IDE integration</td><td>$0.006</td></tr><tr><td>CodeGen</td><td>Salesforce</td><td>Large-scale code generation</td><td>$0.003</td></tr></tbody></table>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#code-generation-models\",\"isPage\":false,\"text\":\"\\nSpecialized for programming tasks:\\nModelProviderSpecializationCost per 1K tokensCodeT5+SalesforceMulti-language code$0.004GitHub CopilotGitHubIDE integration$0.006CodeGenSalesforceLarge-scale code generation$0.003\\n\",\"title\":\"Code Generation Models\",\"titles\":[\"Model Discovery\",\"Model Categories\",\"Language Models\"]},{\"href\":\"/user-guide/model-discovery#vision-models\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#vision-models\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Vision Models\",\"titles\":[\"Model Discovery\",\"Model Categories\"]},{\"href\":\"/user-guide/model-discovery#image-generation\",\"html\":\"\\n<p>Create images from text descriptions:</p>\\n<table><thead><tr><th>Model</th><th>Provider</th><th>Style</th><th>Cost per image</th></tr></thead><tbody><tr><td>DALL-E 3</td><td>OpenAI</td><td>Photorealistic</td><td>$0.040</td></tr><tr><td>Midjourney</td><td>Midjourney</td><td>Artistic</td><td>$0.025</td></tr><tr><td>Stable Diffusion XL</td><td>Stability AI</td><td>Versatile</td><td>$0.015</td></tr></tbody></table>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#image-generation\",\"isPage\":false,\"text\":\"\\nCreate images from text descriptions:\\nModelProviderStyleCost per imageDALL-E 3OpenAIPhotorealistic$0.040MidjourneyMidjourneyArtistic$0.025Stable Diffusion XLStability AIVersatile$0.015\\n\",\"title\":\"Image Generation\",\"titles\":[\"Model Discovery\",\"Model Categories\",\"Vision Models\"]},{\"href\":\"/user-guide/model-discovery#image-analysis\",\"html\":\"\\n<p>Analyze and describe images:</p>\\n<table><thead><tr><th>Model</th><th>Provider</th><th>Capabilities</th><th>Cost per request</th></tr></thead><tbody><tr><td>GPT-4V</td><td>OpenAI</td><td>General vision, OCR</td><td>$0.020</td></tr><tr><td>Claude Vision</td><td>Anthropic</td><td>Document analysis</td><td>$0.018</td></tr><tr><td>LLaVA</td><td>Various</td><td>Open-source vision</td><td>$0.005</td></tr></tbody></table>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#image-analysis\",\"isPage\":false,\"text\":\"\\nAnalyze and describe images:\\nModelProviderCapabilitiesCost per requestGPT-4VOpenAIGeneral vision, OCR$0.020Claude VisionAnthropicDocument analysis$0.018LLaVAVariousOpen-source vision$0.005\\n\",\"title\":\"Image Analysis\",\"titles\":[\"Model Discovery\",\"Model Categories\",\"Vision Models\"]},{\"href\":\"/user-guide/model-discovery#embedding-models\",\"html\":\"\\n<p>For semantic search and similarity:</p>\\n<table><thead><tr><th>Model</th><th>Provider</th><th>Dimensions</th><th>Cost per 1K tokens</th></tr></thead><tbody><tr><td>text-embedding-ada-002</td><td>OpenAI</td><td>1536</td><td>$0.0001</td></tr><tr><td>all-MiniLM-L6-v2</td><td>Sentence Transformers</td><td>384</td><td>$0.0001</td></tr><tr><td>e5-large-v2</td><td>Microsoft</td><td>1024</td><td>$0.0002</td></tr></tbody></table>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#embedding-models\",\"isPage\":false,\"text\":\"\\nFor semantic search and similarity:\\nModelProviderDimensionsCost per 1K tokenstext-embedding-ada-002OpenAI1536$0.0001all-MiniLM-L6-v2Sentence Transformers384$0.0001e5-large-v2Microsoft1024$0.0002\\n\",\"title\":\"Embedding Models\",\"titles\":[\"Model Discovery\",\"Model Categories\"]},{\"href\":\"/user-guide/model-discovery#model-selection-criteria\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#model-selection-criteria\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Model Selection Criteria\",\"titles\":[\"Model Discovery\"]},{\"href\":\"/user-guide/model-discovery#performance-factors\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#performance-factors\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Performance Factors\",\"titles\":[\"Model Discovery\",\"Model Selection Criteria\"]},{\"href\":\"/user-guide/model-discovery#quality-metrics\",\"html\":\"\\n<ul>\\n<li><strong>Accuracy scores</strong> on benchmark datasets</li>\\n<li><strong>Human evaluation ratings</strong> from users</li>\\n<li><strong>Task-specific performance</strong> (BLEU, ROUGE, etc.)</li>\\n<li>\\n<strong>Safety and bias assessments</strong>\\n</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#quality-metrics\",\"isPage\":false,\"text\":\"\\n\\nAccuracy scores on benchmark datasets\\nHuman evaluation ratings from users\\nTask-specific performance (BLEU, ROUGE, etc.)\\n\\nSafety and bias assessments\\n\\n\\n\",\"title\":\"Quality Metrics\",\"titles\":[\"Model Discovery\",\"Model Selection Criteria\",\"Performance Factors\"]},{\"href\":\"/user-guide/model-discovery#speed--efficiency\",\"html\":\"\\n<ul>\\n<li><strong>Average latency</strong> per request</li>\\n<li><strong>Throughput</strong> (requests per second)</li>\\n<li><strong>Time to first token</strong> for streaming</li>\\n<li><strong>Scalability</strong> under load</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#speed--efficiency\",\"isPage\":false,\"text\":\"\\n\\nAverage latency per request\\nThroughput (requests per second)\\nTime to first token for streaming\\nScalability under load\\n\\n\",\"title\":\"Speed &amp; Efficiency\",\"titles\":[\"Model Discovery\",\"Model Selection Criteria\",\"Performance Factors\"]},{\"href\":\"/user-guide/model-discovery#cost-considerations\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#cost-considerations\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Cost Considerations\",\"titles\":[\"Model Discovery\",\"Model Selection Criteria\"]},{\"href\":\"/user-guide/model-discovery#pricing-models\",\"html\":\"\\n<ul>\\n<li><strong>Per-token pricing</strong> for language models</li>\\n<li><strong>Per-image pricing</strong> for generation models</li>\\n<li><strong>Per-request pricing</strong> for embeddings</li>\\n<li><strong>Volume discounts</strong> for high usage</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#pricing-models\",\"isPage\":false,\"text\":\"\\n\\nPer-token pricing for language models\\nPer-image pricing for generation models\\nPer-request pricing for embeddings\\nVolume discounts for high usage\\n\\n\",\"title\":\"Pricing Models\",\"titles\":[\"Model Discovery\",\"Model Selection Criteria\",\"Cost Considerations\"]},{\"href\":\"/user-guide/model-discovery#cost-optimization-tips\",\"html\":\"\\n<ol>\\n<li><strong>Compare providers</strong> for the same model</li>\\n<li><strong>Monitor usage patterns</strong> to identify optimization opportunities</li>\\n<li><strong>Use caching</strong> for repeated requests</li>\\n<li><strong>Choose appropriate model sizes</strong> for your use case</li>\\n</ol>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#cost-optimization-tips\",\"isPage\":false,\"text\":\"\\n\\nCompare providers for the same model\\nMonitor usage patterns to identify optimization opportunities\\nUse caching for repeated requests\\nChoose appropriate model sizes for your use case\\n\\n\",\"title\":\"Cost Optimization Tips\",\"titles\":[\"Model Discovery\",\"Model Selection Criteria\",\"Cost Considerations\"]},{\"href\":\"/user-guide/model-discovery#provider-reliability\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#provider-reliability\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Provider Reliability\",\"titles\":[\"Model Discovery\",\"Model Selection Criteria\"]},{\"href\":\"/user-guide/model-discovery#availability-metrics\",\"html\":\"\\n<ul>\\n<li><strong>Uptime percentage</strong> (99.9%+ recommended)</li>\\n<li><strong>Mean time to recovery</strong> (MTTR)</li>\\n<li><strong>Geographic distribution</strong> for reduced latency</li>\\n<li><strong>Status page</strong> transparency</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#availability-metrics\",\"isPage\":false,\"text\":\"\\n\\nUptime percentage (99.9%+ recommended)\\nMean time to recovery (MTTR)\\nGeographic distribution for reduced latency\\nStatus page transparency\\n\\n\",\"title\":\"Availability Metrics\",\"titles\":[\"Model Discovery\",\"Model Selection Criteria\",\"Provider Reliability\"]},{\"href\":\"/user-guide/model-discovery#model-comparison\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#model-comparison\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Model Comparison\",\"titles\":[\"Model Discovery\"]},{\"href\":\"/user-guide/model-discovery#side-by-side-comparison\",\"html\":\"\\n<p>Use our comparison tool to evaluate models:</p>\\n<pre class=\\\"shiki shiki-themes github-light github-dark-dimmed\\\" style=\\\"background-color:#fff;--shiki-dark-bg:#22272e;color:#24292e;--shiki-dark:#adbac7\\\" tabindex=\\\"0\\\"><code><span class=\\\"line\\\"><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">from</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> aimo </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">import</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> AimoClient</span></span>\\n<span class=\\\"line\\\" data-empty-line=\\\"true\\\"> </span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">client </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> AimoClient(</span><span style=\\\"color:#E36209;--shiki-dark:#F69D50\\\">api_key</span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;your_api_key&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">)</span></span>\\n<span class=\\\"line\\\" data-empty-line=\\\"true\\\"> </span>\\n<span class=\\\"line\\\"><span style=\\\"color:#6A737D;--shiki-dark:#768390\\\"># Compare models for a specific task</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">comparison </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> client.models.compare(</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#E36209;--shiki-dark:#F69D50\\\">    models</span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">[</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;gpt-4&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">, </span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;claude-3&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">, </span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;llama-2-70b&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">],</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#E36209;--shiki-dark:#F69D50\\\">    task</span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;text-summarization&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">,</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#E36209;--shiki-dark:#F69D50\\\">    metrics</span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">[</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;quality&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">, </span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;speed&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">, </span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;cost&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">]</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">)</span></span>\\n<span class=\\\"line\\\" data-empty-line=\\\"true\\\"> </span>\\n<span class=\\\"line\\\"><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\">print</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">(comparison)</span></span></code></pre>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#side-by-side-comparison\",\"isPage\":false,\"text\":\"\\nUse our comparison tool to evaluate models:\\nfrom aimo import AimoClient\\n \\nclient = AimoClient(api_key=&quot;your_api_key&quot;)\\n \\n# Compare models for a specific task\\ncomparison = client.models.compare(\\n    models=[&quot;gpt-4&quot;, &quot;claude-3&quot;, &quot;llama-2-70b&quot;],\\n    task=&quot;text-summarization&quot;,\\n    metrics=[&quot;quality&quot;, &quot;speed&quot;, &quot;cost&quot;]\\n)\\n \\nprint(comparison)\\n\",\"title\":\"Side-by-Side Comparison\",\"titles\":[\"Model Discovery\",\"Model Comparison\"]},{\"href\":\"/user-guide/model-discovery#benchmark-results\",\"html\":\"\\n<p>Popular benchmarks across model types:</p>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#benchmark-results\",\"isPage\":false,\"text\":\"\\nPopular benchmarks across model types:\\n\",\"title\":\"Benchmark Results\",\"titles\":[\"Model Discovery\",\"Model Comparison\"]},{\"href\":\"/user-guide/model-discovery#language-models-1\",\"html\":\"\\n<ul>\\n<li><strong>MMLU</strong> (Massive Multitask Language Understanding)</li>\\n<li><strong>HellaSwag</strong> (Common sense reasoning)</li>\\n<li><strong>HumanEval</strong> (Code generation)</li>\\n<li><strong>GSM8K</strong> (Mathematical reasoning)</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#language-models-1\",\"isPage\":false,\"text\":\"\\n\\nMMLU (Massive Multitask Language Understanding)\\nHellaSwag (Common sense reasoning)\\nHumanEval (Code generation)\\nGSM8K (Mathematical reasoning)\\n\\n\",\"title\":\"Language Models\",\"titles\":[\"Model Discovery\",\"Model Comparison\",\"Benchmark Results\"]},{\"href\":\"/user-guide/model-discovery#vision-models-1\",\"html\":\"\\n<ul>\\n<li><strong>COCO</strong> (Object detection and segmentation)</li>\\n<li><strong>ImageNet</strong> (Image classification)</li>\\n<li><strong>VQA</strong> (Visual Question Answering)</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#vision-models-1\",\"isPage\":false,\"text\":\"\\n\\nCOCO (Object detection and segmentation)\\nImageNet (Image classification)\\nVQA (Visual Question Answering)\\n\\n\",\"title\":\"Vision Models\",\"titles\":[\"Model Discovery\",\"Model Comparison\",\"Benchmark Results\"]},{\"href\":\"/user-guide/model-discovery#testing-models\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#testing-models\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Testing Models\",\"titles\":[\"Model Discovery\"]},{\"href\":\"/user-guide/model-discovery#quick-testing\",\"html\":\"\\n<p>Test models directly in your browser:</p>\\n<ol>\\n<li>Go to <a href=\\\"https://dashboard.aimo.network/playground\\\">API Playground</a></li>\\n<li>Select a model from the dropdown</li>\\n<li>Enter your prompt or input</li>\\n<li>Adjust parameters (temperature, max tokens, etc.)</li>\\n<li>Run the test and review results</li>\\n</ol>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#quick-testing\",\"isPage\":false,\"text\":\"\\nTest models directly in your browser:\\n\\nGo to API Playground\\nSelect a model from the dropdown\\nEnter your prompt or input\\nAdjust parameters (temperature, max tokens, etc.)\\nRun the test and review results\\n\\n\",\"title\":\"Quick Testing\",\"titles\":[\"Model Discovery\",\"Testing Models\"]},{\"href\":\"/user-guide/model-discovery#programmatic-testing\",\"html\":\"\\n<p>Test multiple models with the same input:</p>\\n<pre class=\\\"shiki shiki-themes github-light github-dark-dimmed\\\" style=\\\"background-color:#fff;--shiki-dark-bg:#22272e;color:#24292e;--shiki-dark:#adbac7\\\" tabindex=\\\"0\\\"><code><span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">models_to_test </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> [</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;gpt-4&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">, </span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;claude-3&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">, </span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;llama-2-70b&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">]</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">prompt </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\"> &quot;Explain quantum computing in simple terms&quot;</span></span>\\n<span class=\\\"line\\\" data-empty-line=\\\"true\\\"> </span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">results </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> {}</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">for</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> model </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">in</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> models_to_test:</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">    response </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> client.chat.completions.create(</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#E36209;--shiki-dark:#F69D50\\\">        model</span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">model,</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#E36209;--shiki-dark:#F69D50\\\">        messages</span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">[{</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;role&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">: </span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;user&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">, </span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;content&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">: prompt}],</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#E36209;--shiki-dark:#F69D50\\\">        max_tokens</span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\">200</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">    )</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">    results[model] </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">=</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> {</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">        &quot;response&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">: response.choices[</span><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\">0</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">].message.content,</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">        &quot;latency&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">: response.meta.latency_ms,</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">        &quot;cost&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">: response.meta.cost</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">    }</span></span>\\n<span class=\\\"line\\\" data-empty-line=\\\"true\\\"> </span>\\n<span class=\\\"line\\\"><span style=\\\"color:#6A737D;--shiki-dark:#768390\\\"># Compare results</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">for</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> model, result </span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">in</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\"> results.items():</span></span>\\n<span class=\\\"line\\\"><span style=\\\"color:#005CC5;--shiki-dark:#6CB6FF\\\">    print</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">(</span><span style=\\\"color:#D73A49;--shiki-dark:#F47067\\\">f</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;</span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\">{</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">model</span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\">}</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">: </span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\">{</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">result[</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&#x27;latency&#x27;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">]</span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\">}</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">ms, $</span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\">{</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">result[</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&#x27;cost&#x27;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">]</span><span style=\\\"color:#005CC5;--shiki-dark:#F47067\\\">}</span><span style=\\\"color:#032F62;--shiki-dark:#96D0FF\\\">&quot;</span><span style=\\\"color:#24292E;--shiki-dark:#ADBAC7\\\">)</span></span></code></pre>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#programmatic-testing\",\"isPage\":false,\"text\":\"\\nTest multiple models with the same input:\\nmodels_to_test = [&quot;gpt-4&quot;, &quot;claude-3&quot;, &quot;llama-2-70b&quot;]\\nprompt = &quot;Explain quantum computing in simple terms&quot;\\n \\nresults = {}\\nfor model in models_to_test:\\n    response = client.chat.completions.create(\\n        model=model,\\n        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],\\n        max_tokens=200\\n    )\\n    results[model] = {\\n        &quot;response&quot;: response.choices[0].message.content,\\n        &quot;latency&quot;: response.meta.latency_ms,\\n        &quot;cost&quot;: response.meta.cost\\n    }\\n \\n# Compare results\\nfor model, result in results.items():\\n    print(f&quot;{model}: {result[&#x27;latency&#x27;]}ms, ${result[&#x27;cost&#x27;]}&quot;)\\n\",\"title\":\"Programmatic Testing\",\"titles\":[\"Model Discovery\",\"Testing Models\"]},{\"href\":\"/user-guide/model-discovery#model-recommendations\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#model-recommendations\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Model Recommendations\",\"titles\":[\"Model Discovery\"]},{\"href\":\"/user-guide/model-discovery#by-use-case\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#by-use-case\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"By Use Case\",\"titles\":[\"Model Discovery\",\"Model Recommendations\"]},{\"href\":\"/user-guide/model-discovery#customer-support-chatbots\",\"html\":\"\\n<p><strong>Recommended</strong>: GPT-3.5 Turbo</p>\\n<ul>\\n<li><strong>Why</strong>: Fast responses, good comprehension, cost-effective</li>\\n<li><strong>Alternative</strong>: Claude-3 for more nuanced conversations</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#customer-support-chatbots\",\"isPage\":false,\"text\":\"\\nRecommended: GPT-3.5 Turbo\\n\\nWhy: Fast responses, good comprehension, cost-effective\\nAlternative: Claude-3 for more nuanced conversations\\n\\n\",\"title\":\"Customer Support Chatbots\",\"titles\":[\"Model Discovery\",\"Model Recommendations\",\"By Use Case\"]},{\"href\":\"/user-guide/model-discovery#content-generation\",\"html\":\"\\n<p><strong>Recommended</strong>: GPT-4</p>\\n<ul>\\n<li><strong>Why</strong>: High quality, creative outputs, good instruction following</li>\\n<li><strong>Alternative</strong>: Claude-3 for specific writing styles</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#content-generation\",\"isPage\":false,\"text\":\"\\nRecommended: GPT-4\\n\\nWhy: High quality, creative outputs, good instruction following\\nAlternative: Claude-3 for specific writing styles\\n\\n\",\"title\":\"Content Generation\",\"titles\":[\"Model Discovery\",\"Model Recommendations\",\"By Use Case\"]},{\"href\":\"/user-guide/model-discovery#code-analysis\",\"html\":\"\\n<p><strong>Recommended</strong>: GPT-4 or CodeT5+</p>\\n<ul>\\n<li><strong>Why</strong>: Strong reasoning, multi-language support</li>\\n<li><strong>Alternative</strong>: GitHub Copilot for IDE integration</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#code-analysis\",\"isPage\":false,\"text\":\"\\nRecommended: GPT-4 or CodeT5+\\n\\nWhy: Strong reasoning, multi-language support\\nAlternative: GitHub Copilot for IDE integration\\n\\n\",\"title\":\"Code Analysis\",\"titles\":[\"Model Discovery\",\"Model Recommendations\",\"By Use Case\"]},{\"href\":\"/user-guide/model-discovery#image-generation-1\",\"html\":\"\\n<p><strong>Recommended</strong>: DALL-E 3</p>\\n<ul>\\n<li><strong>Why</strong>: High quality, good prompt adherence</li>\\n<li><strong>Alternative</strong>: Midjourney for artistic styles</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#image-generation-1\",\"isPage\":false,\"text\":\"\\nRecommended: DALL-E 3\\n\\nWhy: High quality, good prompt adherence\\nAlternative: Midjourney for artistic styles\\n\\n\",\"title\":\"Image Generation\",\"titles\":[\"Model Discovery\",\"Model Recommendations\",\"By Use Case\"]},{\"href\":\"/user-guide/model-discovery#by-budget\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#by-budget\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"By Budget\",\"titles\":[\"Model Discovery\",\"Model Recommendations\"]},{\"href\":\"/user-guide/model-discovery#budget-conscious\",\"html\":\"\\n<ul>\\n<li><strong>Language</strong>: Llama 2, GPT-3.5 Turbo</li>\\n<li><strong>Images</strong>: Stable Diffusion models</li>\\n<li><strong>Embeddings</strong>: Open-source Sentence Transformers</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#budget-conscious\",\"isPage\":false,\"text\":\"\\n\\nLanguage: Llama 2, GPT-3.5 Turbo\\nImages: Stable Diffusion models\\nEmbeddings: Open-source Sentence Transformers\\n\\n\",\"title\":\"Budget-Conscious\",\"titles\":[\"Model Discovery\",\"Model Recommendations\",\"By Budget\"]},{\"href\":\"/user-guide/model-discovery#performance-first\",\"html\":\"\\n<ul>\\n<li><strong>Language</strong>: GPT-4, Claude-3</li>\\n<li><strong>Images</strong>: DALL-E 3, Midjourney Pro</li>\\n<li><strong>Embeddings</strong>: OpenAI Ada-002</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#performance-first\",\"isPage\":false,\"text\":\"\\n\\nLanguage: GPT-4, Claude-3\\nImages: DALL-E 3, Midjourney Pro\\nEmbeddings: OpenAI Ada-002\\n\\n\",\"title\":\"Performance-First\",\"titles\":[\"Model Discovery\",\"Model Recommendations\",\"By Budget\"]},{\"href\":\"/user-guide/model-discovery#staying-updated\",\"html\":\"\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#staying-updated\",\"isPage\":false,\"text\":\"\\n\",\"title\":\"Staying Updated\",\"titles\":[\"Model Discovery\"]},{\"href\":\"/user-guide/model-discovery#new-model-alerts\",\"html\":\"\\n<p>Subscribe to notifications for:</p>\\n<ul>\\n<li><strong>New model releases</strong> in your categories of interest</li>\\n<li><strong>Price changes</strong> from your preferred providers</li>\\n<li><strong>Performance improvements</strong> and updates</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#new-model-alerts\",\"isPage\":false,\"text\":\"\\nSubscribe to notifications for:\\n\\nNew model releases in your categories of interest\\nPrice changes from your preferred providers\\nPerformance improvements and updates\\n\\n\",\"title\":\"New Model Alerts\",\"titles\":[\"Model Discovery\",\"Staying Updated\"]},{\"href\":\"/user-guide/model-discovery#model-versioning\",\"html\":\"\\n<p>Track model versions and updates:</p>\\n<ul>\\n<li><strong>Changelog</strong> for each model version</li>\\n<li><strong>Backward compatibility</strong> information</li>\\n<li><strong>Migration guides</strong> for version upgrades</li>\\n</ul>\\n\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#model-versioning\",\"isPage\":false,\"text\":\"\\nTrack model versions and updates:\\n\\nChangelog for each model version\\nBackward compatibility information\\nMigration guides for version upgrades\\n\\n\",\"title\":\"Model Versioning\",\"titles\":[\"Model Discovery\",\"Staying Updated\"]},{\"href\":\"/user-guide/model-discovery#next-steps\",\"html\":\"\\n<p>Now that you know how to discover models:</p>\\n<ol>\\n<li><strong><a href=\\\"/user-guide/making-requests\\\">Make your first request</a></strong> with a selected model</li>\\n<li><strong><a href=\\\"/user-guide/authentication\\\">Set up authentication</a></strong> for secure access</li>\\n<li><strong><a href=\\\"/user-guide/billing\\\">Monitor usage and costs</a></strong> to optimize spending</li>\\n</ol>\\n<p>Need help choosing? Contact our team at <a href=\\\"mailto:models@aimo.network\\\">models@aimo.network</a> for personalized recommendations.</p>\",\"id\":\"docs/pages/user-guide/model-discovery.mdx#next-steps\",\"isPage\":false,\"text\":\"\\nNow that you know how to discover models:\\n\\nMake your first request with a selected model\\nSet up authentication for secure access\\nMonitor usage and costs to optimize spending\\n\\nNeed help choosing? Contact our team at models@aimo.network for personalized recommendations.\",\"title\":\"Next Steps\",\"titles\":[\"Model Discovery\"]}]}}"
