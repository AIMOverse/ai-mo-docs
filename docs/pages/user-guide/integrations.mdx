# Integration Examples

## OpenAI Python Library Compatibility

You can use the OpenAI Python library with AiMo Network by setting a custom base URL:

```python
import openai

# Configure for AiMo Network
openai.api_base = "https://devnet.aimo.network/api/v1"
openai.api_key = "aimo-sk-dev-[your-api-key]"

# Use as normal, but specify provider:model format
response = openai.ChatCompletion.create(
    model="9WzDXwBbmkg8ZTbNMqUxvQRAyrZzDsGYdLVL9zYtAWWM:gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "Hello, AI!"}
    ]
)
```

## Langchain Integration

```python
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI

# Configure for AiMo Network
chat = ChatOpenAI(
    openai_api_base="https://devnet.aimo.network/api/v1",
    openai_api_key="aimo-sk-dev-xxxxxxx",
    model_name="9WzDXwBbmkg8ZTbNMqUxvQRAyrZzDsGYdLVL9zYtAWWM:gpt-3.5-turbo"
)

response = chat.predict("What is the future of AI?")
```

## Rate Limits and Best Practices

### Performance Optimization

1. **Use Streaming**: Enable streaming for better user experience
2. **Batch Requests**: Group multiple requests when possible
3. **Cache Responses**: Cache responses for repeated queries
4. **Monitor Costs**: Track token usage to optimize costs

### Fair Usage

1. **Respect Rate Limits**: Don't exceed provider-specific rate limits
2. **Optimize Prompts**: Use efficient prompts to reduce token costs
3. **Handle Errors Gracefully**: Implement proper retry logic with exponential backoff
